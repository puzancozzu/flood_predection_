{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "# import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the SUM of all the target features\n",
    "\n",
    "### Getting all the features - that is except \"Flood Probability\" - target feature\n",
    "feature_cols = [x for x in df_train.columns if x != \"FloodProbability\"]\n",
    "\n",
    "# Create a new column 'fsum' which is the sum of all feature columns for each row\n",
    "df_train['fsum'] = df_train[feature_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>...</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "      <th>fsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.445</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.450</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "0   0                 5                   8                5              8   \n",
       "1   1                 6                   7                4              4   \n",
       "2   2                 6                   5                6              7   \n",
       "3   3                 3                   4                6              5   \n",
       "4   4                 5                   3                2              6   \n",
       "\n",
       "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
       "0             6              4            4          3                      3   \n",
       "1             8              8            3          5                      4   \n",
       "2             3              7            1          5                      4   \n",
       "3             4              8            4          7                      6   \n",
       "4             4              4            3          3                      3   \n",
       "\n",
       "   ...  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "0  ...                     3           3           5   \n",
       "1  ...                     2           0           3   \n",
       "2  ...                     3           7           5   \n",
       "3  ...                     4           7           4   \n",
       "4  ...                     2           6           6   \n",
       "\n",
       "   DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0                            4                7            5   \n",
       "1                            5                3            3   \n",
       "2                            6                8            2   \n",
       "3                            4                6            5   \n",
       "4                            4                1            2   \n",
       "\n",
       "   InadequatePlanning  PoliticalFactors  FloodProbability  fsum  \n",
       "0                   7                 3             0.445    94  \n",
       "1                   4                 3             0.450    95  \n",
       "2                   3                 3             0.530   101  \n",
       "3                   7                 5             0.535   107  \n",
       "4                   3                 5             0.415    76  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.loc[:, df_train.columns != \"FloodProbability\"]\n",
    "y = df_train['FloodProbability']\n",
    "\n",
    "# Features Scaling using the Standard Scaler\n",
    "# scaler = QuantileTransformer()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8162489547658828"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using Liner Regression model\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "### fitting the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# making the predections\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "### Evaluate the model\n",
    "r2_score(lr_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8452791832341942\n"
     ]
    }
   ],
   "source": [
    "polynomial = Pipeline([\n",
    "    ('polynomial', PolynomialFeatures(include_bias=False, degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "### Fit the model\n",
    "polynomial.fit(X_train, y_train)\n",
    "poly2_pred = polynomial.predict(X_test)\n",
    "\n",
    "### Calculating R^2 score\n",
    "r2_poly2 = r2_score(y_test, poly2_pred)\n",
    "print(r2_poly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'alpha': 0.0001, 'eta0': 100, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best R^2 score: 0.8447353322542847\n"
     ]
    }
   ],
   "source": [
    "sgd_regressor = SGDRegressor(random_state=42)\n",
    "\n",
    "\n",
    "### Define hyperparameters for fiting the model\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00005],\n",
    "    'learning_rate': ['constant', 'optimal', 'adaptive'],\n",
    "    'max_iter': [1000, 2000],\n",
    "    'eta0': [1, 10, 100]\n",
    "}\n",
    "    \n",
    "### Grid Search Cross Validation- find the best hyperparameters    \n",
    "grid = GridSearchCV(estimator=sgd_regressor, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "### Get the best model from Grid Search\n",
    "sgd_model = grid.best_estimator_\n",
    "\n",
    "### Fit the model\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "#### Make predictions\n",
    "sgd_pred = sgd_model.predict(X_test)\n",
    "\n",
    "### Evaluate the model\n",
    "r2_sgd = r2_score(y_test, sgd_pred)\n",
    "print(\"Best parameters found:\", grid.best_params_)\n",
    "print(\"Best R^2 score:\", r2_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] END ....................................n_estimators=50; total time=   2.9s\n",
      "[CV] END ....................................n_estimators=50; total time=   2.8s\n",
      "[CV] END ....................................n_estimators=50; total time=   2.7s\n",
      "[CV] END ...................................n_estimators=100; total time=   4.0s\n",
      "[CV] END ...................................n_estimators=100; total time=   4.2s\n",
      "[CV] END ...................................n_estimators=100; total time=   4.1s\n",
      "[CV] END ...................................n_estimators=150; total time=   5.8s\n",
      "[CV] END ...................................n_estimators=150; total time=   5.8s\n",
      "[CV] END ...................................n_estimators=150; total time=   6.1s\n",
      "[CV] END ...................................n_estimators=500; total time=  18.1s\n",
      "[CV] END ...................................n_estimators=500; total time=  18.8s\n",
      "[CV] END ...................................n_estimators=500; total time=  18.5s\n",
      "Best parameters found: {'n_estimators': 500}\n",
      "Best R^2 score: 0.8324104704181869\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model_new = xgb.XGBRegressor(alpha=0.01, eta=0.1, reg_lambda=1, max_depth=7, min_child_weight=7)\n",
    "\n",
    "param_grid_XGBn = {\n",
    "    'n_estimators': [50, 100, 150, 500]\n",
    "}\n",
    "\n",
    "xgb_search_new = GridSearchCV(estimator=xgb_model_new, param_grid=param_grid_XGBn, cv=3, verbose=2)\n",
    "xgb_search_new.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xgb_regressor = xgb_search_new.best_estimator_\n",
    "\n",
    "\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xgb_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "r2_xgb = r2_score(y_test, xgb_pred)\n",
    "print(\"Best parameters found:\", xgb_search_new.best_params_)\n",
    "print(\"Best R^2 score:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('Polynomial Regression', polynomial), \n",
    "                  ('SGDRegressor', sgd_model), ('XGBoostRegressor', xgb_regressor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "SC = StackingRegressor(estimators=estimators, final_estimator= LinearRegression())\n",
    "\n",
    "SC = SC.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "ensemble_preds = SC.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8453854724742271\n"
     ]
    }
   ],
   "source": [
    "r2_ensemble = r2_score(y_test, ensemble_preds)\n",
    "print(r2_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiting the best performace model in overall dataset\n",
    "SC = SC.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = df_test['id']\n",
    "\n",
    "# removing the ids for the dataset\n",
    "# df_test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Create a new column 'fsum' which is the sum of all feature columns for each row\n",
    "df_test['fsum'] = df_test.sum(axis=1) \n",
    "\n",
    "# Scale data\n",
    "df_test = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood Risk Zone - Send alert to people who are in risk zone\n"
     ]
    }
   ],
   "source": [
    "predictions_test = SC.predict(df_test[0].reshape(1,-1))\n",
    "if predictions_test > 0.55:\n",
    "    print(\"Flood Risk Zone - Send alert to people who are in risk zone\")\n",
    "else:\n",
    "    print(\"Do nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'sc_model_new.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"sc_model_new.pkl\", \"wb\") as file:\n",
    "    pickle.dump(SC, file)\n",
    "\n",
    "print(\"Model saved as 'sc_model_new.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from loaded model: [0.57562389 0.45568986 0.45522268 ... 0.62728772 0.551006   0.5097893 ]\n"
     ]
    }
   ],
   "source": [
    "with open(\"sc_model_new.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Use the loaded model for prediction\n",
    "prediction = loaded_model.predict(df_test)\n",
    "print(\"Prediction from loaded model:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe_vev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
